{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, make_scorer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['NORMAL', 'PNEUMONIA']\n",
    "target_size = (150, 150)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "def preprocess_image(img):\n",
    "    img = img.convert('L')  # Convert to grayscale\n",
    "    img = img.resize(target_size)  # Resize image\n",
    "    img_array = np.array(img)  # Convert to numpy array\n",
    "    return img_array\n",
    "\n",
    "def load_data(data_dir):\n",
    "    for label, category in enumerate(categories):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for filename in os.listdir(category_dir):\n",
    "            if filename.endswith('.jpeg'):\n",
    "                img_path = os.path.join(category_dir, filename)\n",
    "                with Image.open(img_path) as img:\n",
    "                    img_array = preprocess_image(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label)\n",
    "\n",
    "def create_model(optimizer='adam', dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    # model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['recall'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    load_data('./chest_Xray/DATA')\n",
    "    print(\"Data loaded\")\n",
    "\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Normalize pixel values to between 0 and 1\n",
    "    X = X / 255.0\n",
    "\n",
    "    # Reshape for CNN\n",
    "    X = X.reshape(-1, target_size[0], target_size[1], 1)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Emballer le modèle Keras avec KerasClassifier\n",
    "    # create_model_partial = partial(create_model, optimizer='adam')\n",
    "\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    # Définir la grille des hyperparamètres\n",
    "\n",
    "    param_dist = {\n",
    "        'optimizer': ['adam', 'rmsprop'],\n",
    "        # 'dropout_rate': [0.0, 0.2, 0.5],\n",
    "        'batch_size': [16, 32, 64],\n",
    "        'epochs': [10, 20]\n",
    "    }\n",
    "\n",
    "\n",
    "    def recall_scorer(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred)\n",
    "\n",
    "    # Créer un scorer sklearn pour la recherche aléatoire\n",
    "    recall = make_scorer(recall_scorer, greater_is_better=True)\n",
    "\n",
    "    # Initialiser RandomizedSearchCV avec scorer personnalisé\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3, scoring=recall, verbose=2, n_jobs=-1)\n",
    "\n",
    "    # Exécuter la recherche aléatoire\n",
    "    random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Afficher les meilleurs hyperparamètres\n",
    "    print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "\n",
    "    # Utiliser les meilleurs hyperparamètres pour évaluer le modèle sur l'ensemble de validation\n",
    "    best_model = random_result.best_estimator_\n",
    "    val_score = best_model.score(X_test, y_test)\n",
    "    print(f\"Validation recall: {val_score}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
